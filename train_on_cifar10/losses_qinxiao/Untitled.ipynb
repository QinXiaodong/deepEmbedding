{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 32\n",
    "input_dim = 3\n",
    "output_dim = 2\n",
    "num_class = 4\n",
    "x = Variable(torch.rand(data_size, input_dim), requires_grad=False)\n",
    "w = Variable(torch.rand(input_dim, output_dim), requires_grad=True)\n",
    "inputs = x.mm(w)\n",
    "y_ = 8*list(range(num_class))\n",
    "targets = Variable(torch.IntTensor(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.random.rand(data_size,input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=np.array(8*list(range(num_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('inputs.npy',inputs)\n",
    "np.save('targets.npy',targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3324, 0.6856, 0.1523],\n",
       "        [0.7529, 0.7688, 0.6183],\n",
       "        [0.2742, 0.2200, 0.9693],\n",
       "        [0.4818, 0.5265, 0.8199],\n",
       "        [0.9567, 0.6536, 0.7073],\n",
       "        [0.1343, 0.0573, 0.3201],\n",
       "        [0.5711, 0.7084, 0.4961],\n",
       "        [0.1555, 0.7137, 0.9226],\n",
       "        [0.8204, 0.1300, 0.8127],\n",
       "        [0.9781, 0.2432, 0.8335],\n",
       "        [0.5221, 0.4624, 0.9861],\n",
       "        [0.4376, 0.8552, 0.6484],\n",
       "        [0.8922, 0.0657, 0.1166],\n",
       "        [0.7064, 0.5949, 0.1227],\n",
       "        [0.0469, 0.9482, 0.6797],\n",
       "        [0.1598, 0.9735, 0.6525],\n",
       "        [0.3287, 0.8011, 0.2352],\n",
       "        [0.7624, 0.4998, 0.2242],\n",
       "        [0.8136, 0.8486, 0.2725],\n",
       "        [0.2237, 0.8923, 0.6831],\n",
       "        [0.5758, 0.4865, 0.0819],\n",
       "        [0.7716, 0.8008, 0.0637],\n",
       "        [0.4058, 0.8306, 0.7508],\n",
       "        [0.5420, 0.4746, 0.9838],\n",
       "        [0.7328, 0.3135, 0.9274],\n",
       "        [0.6032, 0.6289, 0.3127],\n",
       "        [0.2992, 0.6876, 0.5736],\n",
       "        [0.4998, 0.7625, 0.1210],\n",
       "        [0.0325, 0.0674, 0.0866],\n",
       "        [0.0953, 0.4300, 0.8032],\n",
       "        [0.3126, 0.8290, 0.8315],\n",
       "        [0.7491, 0.1111, 0.4400]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=torch.zeros(targets.shape[0], targets.max()+1).scatter_(1,torch.unsqueeze(targets.long(),1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=torch.from_numpy(np.load('targets.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_instances_per_appeared_class=torch.unsqueeze(targets.sum(0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_instances_per_appeared_class=targets.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.0000, 8.0000, 8.0000, 8.0000])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_instances_per_appeared_class[num_of_instances_per_appeared_class!=0]+=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.rand(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=torch.zeros(targets.shape[0], targets.max()+1).scatter_(1,torch.unsqueeze(targets.long(),1), 1)#转成one_hot编码\n",
    "num_of_instances_per_appeared_class=torch.unsqueeze(targets.sum(0),1)\n",
    "num_of_instances_per_appeared_class[num_of_instances_per_appeared_class==0]=1e-6#避免除零操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.],\n",
       "        [8.],\n",
       "        [8.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_instances_per_appeared_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposedTargets=targets.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_embeddings_per_appeared_class=transposedTargets.mm(inputs.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_per_appeared_class=sum_of_embeddings_per_appeared_class/num_of_instances_per_appeared_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_diff_per_instance=(inputs.float()-torch.index_select(input=mean_embedding_per_appeared_class,dim=0,index=targets.long()))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_square_diff_per_appeared_class=torch.mm(transposedTargets,square_diff_per_instance).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_square_diff_per_appeared_class=torch.unsqueeze(sum_of_square_diff_per_appeared_class,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2840],\n",
       "        [0.2240],\n",
       "        [0.1490],\n",
       "        [0.1756]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_of_embeddings_per_appeared_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_of_embeddings_per_appeared_class=sum_of_square_diff_per_appeared_class/num_of_instances_per_appeared_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pairwise_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7321e-06, 1.7321e-06, 1.7321e-06, 1.7321e-06])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distance(mean_embedding_per_appeared_class,mean_embedding_per_appeared_class,p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanded_pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    if y is not None:\n",
    "         differences = x.unsqueeze(1) - y.unsqueeze(0)\n",
    "    else:\n",
    "        differences = x.unsqueeze(1) - x.unsqueeze(0)\n",
    "    distances = torch.sum(differences * differences, -1)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_loss_matrix=expanded_pairwise_distances(mean_embedding_per_appeared_class)\n",
    "intra_loss_matrix=var_of_embeddings_per_appeared_class+var_of_embeddings_per_appeared_class.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5680, 1.4967, 1.3225, 1.3511]), tensor([0, 0, 3, 3]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(intra_loss_matrix-inter_loss_matrix+1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_matrix=intra_loss_matrix-inter_loss_matrix+1\n",
    "loss_matrix[loss_matrix<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_matrix=loss_matrix-torch.eye(loss_matrix.shape[0])*loss_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4967)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(loss_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
